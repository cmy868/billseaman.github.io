---
layout: subpagepost
section_id: portfolio
title: Navigating Sound Architectures of The Night, Empac
---
<div class="full">
    <div class="row">
        <div class="large-12 large-centered columns">
            <img src="../images/assets/Picture44.png">
            <img src="../images/assets/Picture45.png">
     </div>
    </div>
    <div class="Text_works">
        <h4>Overview</h4>
        <p>
The Work "Navigating and Negotiating Sound Architectures of the Night" is
a major evocative multi-media black box theatre work. Its hybrid form includes 3d
architectonic models that are both virtual and physical; digital video; a generative
visual system including 4 real-time projections; 10 live musical improvisers; a
generative soundtrack; a recorded spoken poetic text; and interactive interface
table enabling multiple interactants to explore the work simultaneously.   </p>
        <h4>Description</h4>
        <p>The work engages with the poetics of night through an interactive structure of 84
            abstract architectural models that are explored over time through multiple sonic /
            architectonic movements; through placement and spatial movement /
            displacement; as well through architectural abstraction. A specially designed
            glass interface table enables participants from the general public to interact with
            the work and become part of the performance via this intuitive multi-user
            interface. A computational sensing system and specially authored computer code
            enables one to juxtapose projection-like texture maps of night-related
            architectural / city-scape imagery, forming large format virtual / architectural
            landscapes presented as 4 large scale projections in the space. Each projection
            contains the view visible from a particular side of the table. A seven movement
            generative/interactive musical score is also driven via the interactive choices of
            the participants; and a series of 10 live audio improvisers also add additional
            layers to the interactive musical score. Multiple architectonic sculptures become
            part of the "set". A poetic text related to the night theme is also enfolded as part
            of the environment. The work is highly interdisciplinary and students from over 5
            departments at Rensselaer Polytechnic Institute have been participating over the
            course of the year.
            </p>
            <h4>Pieces – Physical Interface Units</h4>
            <p>Each of the 84 physical interface architectural primitives (physical architectural
                model shapes) are robust in nature — many people interacted with them during
                the performance; each piece is recognized by the system through a unique
                symbol on the bottom of the architectonic form. An additional set of objects can
                be placed next to the models and create architectural abstractions in real time on
                the display screens. This makes the work extremely flexible in terms of real-time
                exploration of architectonic forms and related texture maps. The architectural
                models have been made of many different materials – wood, metal, plastic (3D
                printed) etc. Usability tests were done related to which materials would work
                Best.
                </p>
            <h4>3d Projection – A set of computer programmers worked in conjunction with
                “Model” designers.</h4>
            <p>For each physical piece an isomorphic form was made with 3D modelling
                software. The programmer facilitated “parallel” spatial moves in the “projected
                space” to that of the movement of the object on the interface table. A “Night”
                video landscape was also projected behind the 3d Models/texture maps. Thus a
                kind of 1-1 relation was formed and brought to life via computer code. For each
                piece a set of texture maps was developed.
                <br><br>
                A series of music loops were developed by Seaman before the performance,
                working in tandem with student members contributing sonic materials that were
                folded into the mix. These loops were “attached” by the programmer to each
                object. Each time an architectural model was put down on the table that loop was
                played back in the room. The room reproduced the spatial positioning of the
                objects on the table and as participants moved the objects, their loop moved in
                physical space forming a dynamic real time spatial mix. Each of the 7
                movements had 12 differing loop/objects and functioned as a generative
                soundtrack. Docents delivered the new objects and cleared the table for each
                new movement.
                <br><br>
                When the participant/interactant placed the object on the glass interface surface,
                the image appeared in real time on one of the screens from a particular
                “perspective” that the programmer had authored. Texture maps also appear on
                the surface of the object at that time as presented on the screen. As discussed
                above the sound had a positionality in real space. When the participant moved
                the piece the sound actually moved to a corresponding location in physical
                space. A dynamic relationality of the pieces was thus achieved though both sonic
                and visual spatial means. The goal was to make a working system where many
                pieces could be put on the table and interacted with via multiple interactants
                simultaneously enabling quick dynamic architectural design capabilities — thus
                the work functioned in part as a real-time multi-user “sketching” tool as well as
                artwork generator.
                <br><br>
                Once this goal was achieved, we authored higher level functionalities that related
                to the proximity of one object to another, and/or the functionality of one set of
                objects that could functionally abstract the architectonic qualities of the original
                object – e.g. make differing algorithmic abstractions of the objects including the
                following— making the selected objects bend; multiply; deform or twist; as well
                as make them more or less transparent; change the scale of the objects that are
                projected; and/or change the height of the objects.
                </p>
                <h4>The Interface Table</h4>
                <p>
                    The interface table had a sensing system that read the symbols affixed to each object via an infrared camera. The table was robust and inspired in part by the
                    initial open source specifications provided by Todd Berreth (Seaman’s
                    collaborator at Duke). The table was later fully re-designed by the team. The
                    room had 4 major screens as one component of the work each providing a
                    differing view of the architectural models covered in texture maps, with an
                    additional slow moving/pulsing video texture map as background. This physical
                    interface table empowered dialogue between participants standing adjacent to
                    the table who in real time manipulated architectural models/projections/sound
                    positioning. Over the course of the evening literally hundreds of participants
                    explored the system!
                    <br><br>
                    Being the main focus, the table was placed in the center of the room. The 12’x16’
                    screens were placed 8’ above the ground, tilted at an angle that was comfortable
                    for audience members to see. The luminous screens together formed a large
                    central space that with the table created a space that was the focus of the
                    performance, though the participants were allowed to move freely within the
                    room. The projectors were placed in the corners of the room, rear projecting onto
                    the screens. </p>
                    <h4>Live performers in the Space / Generative Audio system</h4>
                    <p>

                    </p>
               
        </div> 
      